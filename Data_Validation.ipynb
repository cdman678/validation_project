{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Intro\n",
    "    This notebook serves as a demonstration to the data validation functions created for this project.\n",
    "    There are three primary functions created that aim at validating data\n",
    "\n",
    "    1) Validation of the data set. Checking for \"hidden\" issues in the data\n",
    "        - Outliers\n",
    "        - Dupplicate Data\n",
    "        - Balance -- TODO\n",
    "        - Correlation -- TODO\n",
    "\n",
    "    2) Validation of the Train / Test Split\n",
    "        -\n",
    "        -\n",
    "        -\n",
    "        -\n",
    "        -\n",
    "\n",
    "    3) Creation of a validation data set\n",
    "        -\n",
    "        -\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as  np\n",
    "\n",
    "from scipy.stats import ks_2samp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "def find_outliers(data_df, categorical_threshold=0.1):\n",
    "    \"\"\"\n",
    "    :param data_df: Pandas DataFrame Containing the Data in question\n",
    "    :param categorical_threshold: The frequency threshold to mark a categorical value as an outlier\n",
    "    :return: A Pandas DataFrame listing the index of all outlier values\n",
    "\n",
    "    This function cycles through the column in the provided data and looks for outliers\n",
    "    There are two checks that are preformed.\n",
    "        1) Checking if a categorical column contains any values that fall below the acceptable frequency threshold and thus an outlier\n",
    "        2) Checking if a numerical column contains any statistical outliers, identified using IQR values\n",
    "    \"\"\"\n",
    "\n",
    "    outlier_df = pd.DataFrame(columns=[\"Column\",\"Value\",\"Index\",\"Issue\"])\n",
    "    for col in data_df.columns:\n",
    "        print(data_df[col].dtype)\n",
    "        if data_df[col].dtype == 'object' and all(isinstance(val, str) for val in data_df[col]):\n",
    "            freq = data_df[col].value_counts(normalize=True)\n",
    "            outlier_values = freq[freq < categorical_threshold].index\n",
    "            outliers = test[test[col].isin(outlier_values)]\n",
    "        elif data_df[col].dtype in [\"float64\",\"int64\"]:\n",
    "            q1 = data_df[col].quantile(0.25)\n",
    "            q3 =  data_df[col].quantile(0.75)\n",
    "            iqr = q3 - q1\n",
    "            outliers = data_df[(data_df[col] < (q1 - 1.5 * iqr)) | (data_df[col] > (q3 + 1.5 * iqr))][col]\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # Prepare the temp \"outliers\" DF to be concatenated with the main outlier_df\n",
    "        outliers = outliers.reset_index()\n",
    "        outliers[\"Column\"] = col\n",
    "        outliers = outliers.rename(columns={\"index\":\"Index\",col:\"Value\"})\n",
    "        outliers = outliers[[\"Column\",\"Value\",\"Index\"]]\n",
    "        outliers[\"Issue\"] = \"Outlier\"\n",
    "        outlier_df = pd.concat([outlier_df, outliers])\n",
    "\n",
    "        return outlier_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "def find_duplicates(data_df):\n",
    "    \"\"\"\n",
    "    :param data_df: Pandas DataFrame Containing the Data in question\n",
    "    :return: A Pandas DataFrame listing the index of all duplicate values\n",
    "    \"\"\"\n",
    "\n",
    "    duplicates = data_df[data_df.duplicated()]\n",
    "    duplicates[\"Column\"] = str(duplicates.columns.values)\n",
    "    duplicates[\"Value\"] = \"N/A\"\n",
    "    duplicates = duplicates.reset_index()\n",
    "    duplicates = duplicates.rename(columns={\"index\":\"Index\"})\n",
    "    duplicates[\"Issue\"] = \"Duplicates\"\n",
    "    duplicates = duplicates[[\"Column\",\"Value\",\"Index\",\"Issue\"]]\n",
    "\n",
    "    return duplicates"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def find_balance(data_df, label):\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def find_correlation(df):\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [],
   "source": [
    "def validate_dataset(data, categorical_threshold, data_type=\"excel\"):\n",
    "\n",
    "    # First step is to determine what was passed in and convert to a DF\n",
    "    if data_type == \"excel\":\n",
    "        data_df = pd.read_excel(data)\n",
    "    elif data_type == \"csv\":\n",
    "        data_df = pd.read_csv(data)\n",
    "    elif data_type == \"df\":\n",
    "        data_df = data\n",
    "    else:\n",
    "        return \"Unexpected Type\"\n",
    "\n",
    "    # Check 1: Find Outliers\n",
    "    outliers = find_outliers(data_df, categorical_threshold=categorical_threshold)\n",
    "\n",
    "    # Check 2:\n",
    "    duplicates = find_duplicates(data_df)\n",
    "\n",
    "    # # Check 3:\n",
    "    # balance = find_balance(data_df, label)\n",
    "    #\n",
    "    # # Check 4:\n",
    "    # correlation = find_correlation(data_df)\n",
    "\n",
    "    issues = pd.concat([outliers,duplicates])\n",
    "    all_issues = issues.groupby(\"Index\")[\"Issue\"].unique().reset_index(name=\"Issues\")\n",
    "\n",
    "    return all_issues\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test_representative(dataset, sample):\n",
    "    return_df = pd.DataFrame(columns=[\"Feature\",\"P_Value\",\"Issue\"])\n",
    "    for feature in dataset.columns:\n",
    "        ks_stat, p_value = ks_2samp(dataset[feature], sample[feature])\n",
    "        # Distributions are not significantly different\n",
    "        if p_value >= 0.05:\n",
    "            pass\n",
    "        # Distributions are significantly different\n",
    "        else:\n",
    "            return_df = pd.concat([return_df,pd.DataFrame([[feature,p_value,\"Not Representative of Dataset\"]],columns=[\"Feature\",\"P_Value\",\"Issue\"])])\n",
    "\n",
    "    return return_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "data": {
      "text/plain": "  Feature  P_Value                          Issue\n0    Test      0.4  Not Representative of Dataset",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Feature</th>\n      <th>P_Value</th>\n      <th>Issue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Test</td>\n      <td>0.4</td>\n      <td>Not Representative of Dataset</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"linear-regression-example/data/Advertising_data.csv\")\n",
    "# test = pd.read_csv(\"Machine-learning-without-any-libraries/6. LDA/Wine.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "data": {
      "text/plain": "      TV  radio  newspaper  sales\n0  230.1   37.8       69.2   2210\n1   44.5   39.3       45.1   1040\n2   17.2   45.9       69.3    930\n3  151.5   41.3       58.5   1850\n4  180.8   10.8       58.4   1290",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TV</th>\n      <th>radio</th>\n      <th>newspaper</th>\n      <th>sales</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>230.1</td>\n      <td>37.8</td>\n      <td>69.2</td>\n      <td>2210</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>44.5</td>\n      <td>39.3</td>\n      <td>45.1</td>\n      <td>1040</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>17.2</td>\n      <td>45.9</td>\n      <td>69.3</td>\n      <td>930</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>151.5</td>\n      <td>41.3</td>\n      <td>58.5</td>\n      <td>1850</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>180.8</td>\n      <td>10.8</td>\n      <td>58.4</td>\n      <td>1290</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "data": {
      "text/plain": "TV           float64\nradio        float64\nnewspaper    float64\nsales          int64\ndtype: object"
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.dtypes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Caleb\\AppData\\Local\\Temp\\ipykernel_146188\\3527661167.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  duplicates[\"Column\"] = str(duplicates.columns.values)\n",
      "C:\\Users\\Caleb\\AppData\\Local\\Temp\\ipykernel_146188\\3527661167.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  duplicates[\"Value\"] = \"N/A\"\n"
     ]
    },
    {
     "data": {
      "text/plain": "   Index        Issues\n0      5  [Duplicates]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Index</th>\n      <th>Issues</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>[Duplicates]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = validate_dataset(test, categorical_threshold=0.1, data_type=\"df\")\n",
    "x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample dataframe with duplicate rows\n",
    "data = {'col1': ['a', 'b', 'c', 'd', 'e', 'a'],\n",
    "        'col2': [1, 2, 3, 4, 5, 1]}\n",
    "test = pd.DataFrame(data)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Caleb\\AppData\\Local\\Temp\\ipykernel_146188\\3527661167.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  duplicates[\"Column\"] = str(duplicates.columns.values)\n",
      "C:\\Users\\Caleb\\AppData\\Local\\Temp\\ipykernel_146188\\3527661167.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  duplicates[\"Value\"] = \"N/A\"\n"
     ]
    },
    {
     "data": {
      "text/plain": "            Column Value  Index       Issue\n0  ['col1' 'col2']   N/A      5  Duplicates",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Column</th>\n      <th>Value</th>\n      <th>Index</th>\n      <th>Issue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>['col1' 'col2']</td>\n      <td>N/A</td>\n      <td>5</td>\n      <td>Duplicates</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_duplicates(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
